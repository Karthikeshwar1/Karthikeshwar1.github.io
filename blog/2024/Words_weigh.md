# Words Weigh

Non-living objects communicate through physics (the 4 fundamental forces, chemical bonds, etc)

## 1

Non-human living objects (microscopic/animals/birds/etc.) communicate with a little more sophisticated ways, 
but they're not self-aware (not to level of humans). 
If some exceptional animal did learn to be self-aware, like a üê¨ or an ü¶ß, 
what it speaks wouldn't be understandable by its friends.

1. Human communication is a highly sophisticated mechanism, thanks to the big brain.
   This communication is a result of years of understanding of reality .
   Hence our words reflect the real world and its laws. 
2. Also, since humans are the most self-aware species, the words carry a lot of importance.
   Now, some animals can sing and have complicated sounds as well, but they're neither self-aware,
   nor do their sounds have the level of complexity as humans do. 
3. Also, a single human speaking in a desert carries no importance.
Hence, words only have meaning when the species is social.

<br>

## 2 

Jordan Peterson, in his *Biblical Series* lectures, emphasizes this psychological and symbolic interpretation: that naming and narrative are the human methods of imposing order on a pre-existing chaos ‚Äî the world already exists, but it becomes intelligible, usable, and meaningful once it is named and structured in language ([Jordan Peterson ‚Äì Biblical Series](https://www.jordanbpeterson.com/bible-series/)). (Also see my *Myth Truth* blog for a deeper discussion of this idea.)

Words also have importance in another way: nothing in this world had a *name* until humans named it. Meaning did not arise from atoms alone, but from symbols layered onto reality. The world may have existed before language, but it did not exist *as a world* ‚Äî a structured domain of significance ‚Äî until it was articulated.

<br>

## 3 


This idea echoes powerfully in modern technology. Today‚Äôs large language models ‚Äî the artificial ‚Äúintelligence‚Äù we interact with ‚Äî are built entirely from words. LLMs are statistical systems trained on massive corpora of text, learning relationships between symbols and generating new ones ([OpenAI ‚Äì How ChatGPT Works](https://openai.com/research/chatgpt), [IBM ‚Äì What Are Large Language Models?](https://www.ibm.com/think/topics/large-language-models)). They demonstrate that words alone can generate planning, reasoning-like behavior, and creativity ‚Äî while also reminding us that syntax and prediction are not the same as lived meaning.

Some holy scriptures (Hindu and Christian - I haven't read them) seemed to have said that the capacity that words have to shape reality is akin to the process that generates reality itself.

<br>
<br>
